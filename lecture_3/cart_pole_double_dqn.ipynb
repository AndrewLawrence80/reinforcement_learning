{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cart Pole DQN Solution\n",
    "\n",
    "![cart_pole](../images/lecture_3/cart_pole.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gym Description\n",
    "\n",
    "### Description\n",
    "\n",
    "This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson in\n",
    "[\"Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problem\"](https://ieeexplore.ieee.org/document/6313077).\n",
    "A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track.\n",
    "The pendulum is placed upright on the cart and the goal is to balance the pole by applying forces\n",
    "in the left and right direction on the cart.\n",
    "\n",
    "### Action Space\n",
    "\n",
    "The action is a `ndarray` with shape `(1,)` which can take values `{0, 1}` indicating the direction\n",
    "of the fixed force the cart is pushed with.\n",
    "\n",
    "- 0: Push cart to the left\n",
    "- 1: Push cart to the right\n",
    "\n",
    "**Note**: The velocity that is reduced or increased by the applied force is not fixed and it depends on the angle\n",
    "the pole is pointing. The center of gravity of the pole varies the amount of energy needed to move the cart underneath it\n",
    "\n",
    "### Observation Space\n",
    "\n",
    "The observation is a `ndarray` with shape `(4,)` with the values corresponding to the following positions and velocities:\n",
    "\n",
    "| Num | Observation           | Min                 | Max               |\n",
    "| --- | --------------------- | ------------------- | ----------------- |\n",
    "| 0   | Cart Position         | -4.8                | 4.8               |\n",
    "| 1   | Cart Velocity         | -Inf                | Inf               |\n",
    "| 2   | Pole Angle            | ~ -0.418 rad (-24°) | ~ 0.418 rad (24°) |\n",
    "| 3   | Pole Angular Velocity | -Inf                | Inf               |\n",
    "\n",
    "**Note:** While the ranges above denote the possible values for observation space of each element,\n",
    "it is not reflective of the allowed values of the state space in an unterminated episode. Particularly:\n",
    "\n",
    "- The cart x-position (index 0) can be take values between `(-4.8, 4.8)`, but the episode terminates\n",
    "  if the cart leaves the `(-2.4, 2.4)` range.\n",
    "- The pole angle can be observed between `(-.418, .418)` radians (or **±24°**), but the episode terminates\n",
    "  if the pole angle is not in the range `(-.2095, .2095)` (or **±12°**)\n",
    "\n",
    "### Rewards\n",
    "\n",
    "Since the goal is to keep the pole upright for as long as possible, a reward of `+1` for every step taken,\n",
    "including the termination step, is allotted. The threshold for rewards is 475 for v1.\n",
    "\n",
    "### Starting State\n",
    "\n",
    "All observations are assigned a uniformly random value in `(-0.05, 0.05)`\n",
    "\n",
    "### Episode End\n",
    "\n",
    "The episode ends if any one of the following occurs:\n",
    "\n",
    "1. Termination: Pole Angle is greater than ±12°\n",
    "2. Termination: Cart Position is greater than ±2.4 (center of the cart reaches the edge of the display)\n",
    "3. Truncation: Episode length is greater than 500 (200 for v0)\n",
    "\n",
    "### Arguments\n",
    "\n",
    "```python\n",
    "import gymnasium as gym\n",
    "gym.make('CartPole-v1')\n",
    "```\n",
    "\n",
    "On reset, the `options` parameter allows the user to change the bounds used to determine\n",
    "the new random state.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Jupyter Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7f794e622560>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CartPole-v0\tEnvSpec(id='CartPole-v0', entry_point='gymnasium.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=195.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CartPole', version=0, additional_wrappers=(), vector_entry_point='gymnasium.envs.classic_control.cartpole:CartPoleVectorEnv')\n",
      "CartPole-v1\tEnvSpec(id='CartPole-v1', entry_point='gymnasium.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=475.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CartPole', version=1, additional_wrappers=(), vector_entry_point='gymnasium.envs.classic_control.cartpole:CartPoleVectorEnv')\n",
      "MountainCar-v0\tEnvSpec(id='MountainCar-v0', entry_point='gymnasium.envs.classic_control.mountain_car:MountainCarEnv', reward_threshold=-110.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='MountainCar', version=0, additional_wrappers=(), vector_entry_point=None)\n",
      "MountainCarContinuous-v0\tEnvSpec(id='MountainCarContinuous-v0', entry_point='gymnasium.envs.classic_control.continuous_mountain_car:Continuous_MountainCarEnv', reward_threshold=90.0, nondeterministic=False, max_episode_steps=999, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='MountainCarContinuous', version=0, additional_wrappers=(), vector_entry_point=None)\n",
      "Pendulum-v1\tEnvSpec(id='Pendulum-v1', entry_point='gymnasium.envs.classic_control.pendulum:PendulumEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Pendulum', version=1, additional_wrappers=(), vector_entry_point=None)\n",
      "Acrobot-v1\tEnvSpec(id='Acrobot-v1', entry_point='gymnasium.envs.classic_control.acrobot:AcrobotEnv', reward_threshold=-100.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Acrobot', version=1, additional_wrappers=(), vector_entry_point=None)\n",
      "CartPoleJax-v0\tEnvSpec(id='CartPoleJax-v0', entry_point='gymnasium.envs.phys2d.cartpole:CartPoleJaxEnv', reward_threshold=195.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CartPoleJax', version=0, additional_wrappers=(), vector_entry_point='gymnasium.envs.phys2d.cartpole:CartPoleJaxVectorEnv')\n",
      "CartPoleJax-v1\tEnvSpec(id='CartPoleJax-v1', entry_point='gymnasium.envs.phys2d.cartpole:CartPoleJaxEnv', reward_threshold=475.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CartPoleJax', version=1, additional_wrappers=(), vector_entry_point='gymnasium.envs.phys2d.cartpole:CartPoleJaxVectorEnv')\n",
      "PendulumJax-v0\tEnvSpec(id='PendulumJax-v0', entry_point='gymnasium.envs.phys2d.pendulum:PendulumJaxEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='PendulumJax', version=0, additional_wrappers=(), vector_entry_point='gymnasium.envs.phys2d.pendulum:PendulumJaxVectorEnv')\n",
      "LunarLander-v2\tEnvSpec(id='LunarLander-v2', entry_point='gymnasium.envs.box2d.lunar_lander:LunarLander', reward_threshold=200, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='LunarLander', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "LunarLanderContinuous-v2\tEnvSpec(id='LunarLanderContinuous-v2', entry_point='gymnasium.envs.box2d.lunar_lander:LunarLander', reward_threshold=200, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'continuous': True}, namespace=None, name='LunarLanderContinuous', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "BipedalWalker-v3\tEnvSpec(id='BipedalWalker-v3', entry_point='gymnasium.envs.box2d.bipedal_walker:BipedalWalker', reward_threshold=300, nondeterministic=False, max_episode_steps=1600, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='BipedalWalker', version=3, additional_wrappers=(), vector_entry_point=None)\n",
      "BipedalWalkerHardcore-v3\tEnvSpec(id='BipedalWalkerHardcore-v3', entry_point='gymnasium.envs.box2d.bipedal_walker:BipedalWalker', reward_threshold=300, nondeterministic=False, max_episode_steps=2000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'hardcore': True}, namespace=None, name='BipedalWalkerHardcore', version=3, additional_wrappers=(), vector_entry_point=None)\n",
      "CarRacing-v2\tEnvSpec(id='CarRacing-v2', entry_point='gymnasium.envs.box2d.car_racing:CarRacing', reward_threshold=900, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CarRacing', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "Blackjack-v1\tEnvSpec(id='Blackjack-v1', entry_point='gymnasium.envs.toy_text.blackjack:BlackjackEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'sab': True, 'natural': False}, namespace=None, name='Blackjack', version=1, additional_wrappers=(), vector_entry_point=None)\n",
      "FrozenLake-v1\tEnvSpec(id='FrozenLake-v1', entry_point='gymnasium.envs.toy_text.frozen_lake:FrozenLakeEnv', reward_threshold=0.7, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'map_name': '4x4'}, namespace=None, name='FrozenLake', version=1, additional_wrappers=(), vector_entry_point=None)\n",
      "FrozenLake8x8-v1\tEnvSpec(id='FrozenLake8x8-v1', entry_point='gymnasium.envs.toy_text.frozen_lake:FrozenLakeEnv', reward_threshold=0.85, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'map_name': '8x8'}, namespace=None, name='FrozenLake8x8', version=1, additional_wrappers=(), vector_entry_point=None)\n",
      "CliffWalking-v0\tEnvSpec(id='CliffWalking-v0', entry_point='gymnasium.envs.toy_text.cliffwalking:CliffWalkingEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CliffWalking', version=0, additional_wrappers=(), vector_entry_point=None)\n",
      "Taxi-v3\tEnvSpec(id='Taxi-v3', entry_point='gymnasium.envs.toy_text.taxi:TaxiEnv', reward_threshold=8, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Taxi', version=3, additional_wrappers=(), vector_entry_point=None)\n",
      "Jax-Blackjack-v0\tEnvSpec(id='Jax-Blackjack-v0', entry_point='gymnasium.envs.tabular.blackjack:BlackJackJaxEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'sutton_and_barto': True, 'natural': False}, namespace=None, name='Jax-Blackjack', version=0, additional_wrappers=(), vector_entry_point=None)\n",
      "Reacher-v2\tEnvSpec(id='Reacher-v2', entry_point='gymnasium.envs.mujoco:ReacherEnv', reward_threshold=-3.75, nondeterministic=False, max_episode_steps=50, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Reacher', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "Reacher-v4\tEnvSpec(id='Reacher-v4', entry_point='gymnasium.envs.mujoco.reacher_v4:ReacherEnv', reward_threshold=-3.75, nondeterministic=False, max_episode_steps=50, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Reacher', version=4, additional_wrappers=(), vector_entry_point=None)\n",
      "Pusher-v2\tEnvSpec(id='Pusher-v2', entry_point='gymnasium.envs.mujoco:PusherEnv', reward_threshold=0.0, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Pusher', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "Pusher-v4\tEnvSpec(id='Pusher-v4', entry_point='gymnasium.envs.mujoco.pusher_v4:PusherEnv', reward_threshold=0.0, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Pusher', version=4, additional_wrappers=(), vector_entry_point=None)\n",
      "InvertedPendulum-v2\tEnvSpec(id='InvertedPendulum-v2', entry_point='gymnasium.envs.mujoco:InvertedPendulumEnv', reward_threshold=950.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='InvertedPendulum', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "InvertedPendulum-v4\tEnvSpec(id='InvertedPendulum-v4', entry_point='gymnasium.envs.mujoco.inverted_pendulum_v4:InvertedPendulumEnv', reward_threshold=950.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='InvertedPendulum', version=4, additional_wrappers=(), vector_entry_point=None)\n",
      "InvertedDoublePendulum-v2\tEnvSpec(id='InvertedDoublePendulum-v2', entry_point='gymnasium.envs.mujoco:InvertedDoublePendulumEnv', reward_threshold=9100.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='InvertedDoublePendulum', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "InvertedDoublePendulum-v4\tEnvSpec(id='InvertedDoublePendulum-v4', entry_point='gymnasium.envs.mujoco.inverted_double_pendulum_v4:InvertedDoublePendulumEnv', reward_threshold=9100.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='InvertedDoublePendulum', version=4, additional_wrappers=(), vector_entry_point=None)\n",
      "HalfCheetah-v2\tEnvSpec(id='HalfCheetah-v2', entry_point='gymnasium.envs.mujoco:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='HalfCheetah', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "HalfCheetah-v3\tEnvSpec(id='HalfCheetah-v3', entry_point='gymnasium.envs.mujoco.half_cheetah_v3:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='HalfCheetah', version=3, additional_wrappers=(), vector_entry_point=None)\n",
      "HalfCheetah-v4\tEnvSpec(id='HalfCheetah-v4', entry_point='gymnasium.envs.mujoco.half_cheetah_v4:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='HalfCheetah', version=4, additional_wrappers=(), vector_entry_point=None)\n",
      "Hopper-v2\tEnvSpec(id='Hopper-v2', entry_point='gymnasium.envs.mujoco:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Hopper', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "Hopper-v3\tEnvSpec(id='Hopper-v3', entry_point='gymnasium.envs.mujoco.hopper_v3:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Hopper', version=3, additional_wrappers=(), vector_entry_point=None)\n",
      "Hopper-v4\tEnvSpec(id='Hopper-v4', entry_point='gymnasium.envs.mujoco.hopper_v4:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Hopper', version=4, additional_wrappers=(), vector_entry_point=None)\n",
      "Swimmer-v2\tEnvSpec(id='Swimmer-v2', entry_point='gymnasium.envs.mujoco:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Swimmer', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "Swimmer-v3\tEnvSpec(id='Swimmer-v3', entry_point='gymnasium.envs.mujoco.swimmer_v3:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Swimmer', version=3, additional_wrappers=(), vector_entry_point=None)\n",
      "Swimmer-v4\tEnvSpec(id='Swimmer-v4', entry_point='gymnasium.envs.mujoco.swimmer_v4:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Swimmer', version=4, additional_wrappers=(), vector_entry_point=None)\n",
      "Walker2d-v2\tEnvSpec(id='Walker2d-v2', entry_point='gymnasium.envs.mujoco:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Walker2d', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "Walker2d-v3\tEnvSpec(id='Walker2d-v3', entry_point='gymnasium.envs.mujoco.walker2d_v3:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Walker2d', version=3, additional_wrappers=(), vector_entry_point=None)\n",
      "Walker2d-v4\tEnvSpec(id='Walker2d-v4', entry_point='gymnasium.envs.mujoco.walker2d_v4:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Walker2d', version=4, additional_wrappers=(), vector_entry_point=None)\n",
      "Ant-v2\tEnvSpec(id='Ant-v2', entry_point='gymnasium.envs.mujoco:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Ant', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "Ant-v3\tEnvSpec(id='Ant-v3', entry_point='gymnasium.envs.mujoco.ant_v3:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Ant', version=3, additional_wrappers=(), vector_entry_point=None)\n",
      "Ant-v4\tEnvSpec(id='Ant-v4', entry_point='gymnasium.envs.mujoco.ant_v4:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Ant', version=4, additional_wrappers=(), vector_entry_point=None)\n",
      "Humanoid-v2\tEnvSpec(id='Humanoid-v2', entry_point='gymnasium.envs.mujoco:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Humanoid', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "Humanoid-v3\tEnvSpec(id='Humanoid-v3', entry_point='gymnasium.envs.mujoco.humanoid_v3:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Humanoid', version=3, additional_wrappers=(), vector_entry_point=None)\n",
      "Humanoid-v4\tEnvSpec(id='Humanoid-v4', entry_point='gymnasium.envs.mujoco.humanoid_v4:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Humanoid', version=4, additional_wrappers=(), vector_entry_point=None)\n",
      "HumanoidStandup-v2\tEnvSpec(id='HumanoidStandup-v2', entry_point='gymnasium.envs.mujoco:HumanoidStandupEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='HumanoidStandup', version=2, additional_wrappers=(), vector_entry_point=None)\n",
      "HumanoidStandup-v4\tEnvSpec(id='HumanoidStandup-v4', entry_point='gymnasium.envs.mujoco.humanoidstandup_v4:HumanoidStandupEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='HumanoidStandup', version=4, additional_wrappers=(), vector_entry_point=None)\n",
      "GymV21Environment-v0\tEnvSpec(id='GymV21Environment-v0', entry_point=<function _raise_shimmy_error at 0x7f791927af80>, reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='GymV21Environment', version=0, additional_wrappers=(), vector_entry_point=None)\n",
      "GymV26Environment-v0\tEnvSpec(id='GymV26Environment-v0', entry_point=<function _raise_shimmy_error at 0x7f791927af80>, reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='GymV26Environment', version=0, additional_wrappers=(), vector_entry_point=None)\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.envs.classic_control.cartpole import CartPoleEnv\n",
    "for k, v in gym.envs.registry.items():\n",
    "    print(str(k)+\"\\t\"+str(v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space:  Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "Observation shape:  (4,)\n",
      "Action space:  Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "print(\"Observation space: \", env.observation_space)\n",
    "print(\"Observation shape: \",env.observation_space.shape)\n",
    "print(\"Action space: \", env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Experience:\n",
    "    def __init__(self, maxlen: int) -> None:\n",
    "        # maxlen: if the deque is full, stored items will pop from the head\n",
    "        self.experience = deque([], maxlen=maxlen)\n",
    "\n",
    "    def append(self, transition: List) -> None:\n",
    "        self.experience.append(transition)\n",
    "\n",
    "    def sample(self, batch_size) -> List:\n",
    "        return random.sample(self.experience, batch_size)\n",
    "\n",
    "    def get_length(self) -> int:\n",
    "        return len(self.experience)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pytorch_1.12.1_rl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, num_observations: int, num_actions: int) -> None:\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(num_observations, 128)\n",
    "        self.linear_2 = nn.Linear(128, 128)\n",
    "        self.linear_3 = nn.Linear(128, num_actions)\n",
    "        self.selu = nn.SELU()\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        q_actions = self.linear_1(state)\n",
    "        q_actions = self.selu(q_actions)\n",
    "        q_actions = self.linear_2(q_actions)\n",
    "        q_actions = self.selu(q_actions)\n",
    "        q_actions = self.linear_3(q_actions)\n",
    "        return q_actions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_epsilon(epsilon_start: float, epsilon_end: float, epsilon_decay: int, step_decay: int):\n",
    "    \"\"\"return epsilon: epsilon_end+(epsilon_start-epsilon_end)*e**(-step_decay/epsilon_decay)\"\"\"\n",
    "    return epsilon_end+(epsilon_start-epsilon_end)*np.exp(-1.0*step_decay/epsilon_decay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon-greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def epsilon_greedy(q_approximator: nn.Module, state: torch.Tensor, num_actions: int, epsilon: float):\n",
    "    q_actions = q_approximator(state).detach().cpu().numpy()\n",
    "    probability = np.ones(num_actions)*epsilon/num_actions\n",
    "    idx_action_with_max_q = np.argmax(q_actions)\n",
    "    probability[idx_action_with_max_q] = 1-np.sum(probability[1:])\n",
    "    return np.random.choice(np.arange(num_actions), p=probability)\n",
    "\n",
    "\n",
    "epsilon_greedy(DQN(env.observation_space.shape[0], env.action_space.n), torch.tensor(\n",
    "    env.reset()[0]), env.action_space.n, 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dqn(policy_net:DQN,target_net:DQN,experience:Experience,batch_size:int,gamma:float,loss_fn:nn.Module,optimizer:torch.optim.Optimizer,device:str):\n",
    "    batch=experience.sample(batch_size)\n",
    "    [batch_state,batch_action,batch_next_state,batch_reward]=zip(*batch)\n",
    "    non_final_mask = torch.tensor([next_state is not None for next_state in batch_next_state], dtype=torch.bool,device=device)\n",
    "    non_final_next_states=torch.tensor([next_state for next_state in batch_next_state if next_state is not None],dtype=torch.float32,device=device)\n",
    "    batch_state=torch.tensor(batch_state,dtype=torch.float32,device=device)\n",
    "    batch_action=torch.tensor(batch_action,device=device).unsqueeze(-1)\n",
    "    batch_reward=torch.tensor(batch_reward,dtype=torch.float32,device=device).unsqueeze(-1)\n",
    "    q_state_action=policy_net(batch_state).gather(1,batch_action)\n",
    "    q_next_state_action=torch.zeros(q_state_action.size()).to(device)\n",
    "    # where the difference occurs\n",
    "    with torch.no_grad():\n",
    "        batch_max_action=policy_net(non_final_next_states).max(1)[1].reshape(-1,1)\n",
    "        q_next_state_action[non_final_mask]=target_net(non_final_next_states).gather(1,batch_max_action)\n",
    "    q_target=batch_reward+gamma*q_next_state_action\n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss=loss_fn(q_state_action,q_target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dqn(env:gym.Env,q_approximator:DQN,device:str):\n",
    "    duration=0\n",
    "    state=env.reset()[0]\n",
    "    is_terminated=False\n",
    "    while not is_terminated:\n",
    "        qs_state_action=q_approximator(torch.tensor(state,device=device))\n",
    "        action=torch.argmax(qs_state_action).detach().cpu().item()\n",
    "        next_state,reward,is_terminated,is_truncated,info=env.step(action)\n",
    "        state=next_state\n",
    "        duration+=1\n",
    "        if duration>=2000:\n",
    "            break\n",
    "    print(\"duration: \",duration)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def q_learning(env: gym.Env, num_episodes: int, experience_len: int = 128, batch_size: int = 64, alpha: float = 1e-4, gamma: float = 0.9, epsilon_start: float = 0.9, epsilon_end: float = 0.05, tau=0.005, epsilon_decay: int = 1000, device: str = \"cpu\", print_step=100):\n",
    "\n",
    "    policy_net = DQN(\n",
    "        env.observation_space.shape[0], env.action_space.n).to(device)\n",
    "    target_net = DQN(\n",
    "        env.observation_space.shape[0], env.action_space.n).to(device)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(policy_net.parameters(), lr=alpha)\n",
    "\n",
    "    num_durations_per_episode = defaultdict(int)\n",
    "\n",
    "    experience = Experience(maxlen=experience_len)\n",
    "\n",
    "    step_epsilon_decay = 0\n",
    "\n",
    "    for episode_i in range(num_episodes):\n",
    "        state = env.reset()[0]\n",
    "        is_terminated = False\n",
    "        while not is_terminated:\n",
    "            epsilon = get_epsilon(epsilon_start, epsilon_end,\n",
    "                                  epsilon_decay, step_epsilon_decay)\n",
    "            step_epsilon_decay += 1\n",
    "            action = epsilon_greedy(policy_net, torch.tensor(\n",
    "                state, device=device), env.action_space.n, epsilon)\n",
    "            next_state, reward, is_terminated, is_truncated, info = env.step(\n",
    "                action)\n",
    "            if is_terminated:\n",
    "                next_state = None\n",
    "            experience.append([state, action, next_state, reward])\n",
    "            state = next_state\n",
    "\n",
    "            if experience.get_length() >= batch_size:\n",
    "                update_dqn(policy_net, target_net, experience, batch_size,\n",
    "                           gamma, loss_fn, optimizer, device)\n",
    "\n",
    "            target_net_state_dict = target_net.state_dict()\n",
    "            policy_net_state_dict = policy_net.state_dict()\n",
    "            for key in policy_net_state_dict:\n",
    "                target_net_state_dict[key] = policy_net_state_dict[key] * \\\n",
    "                    tau + target_net_state_dict[key]*(1-tau)\n",
    "            target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "            num_durations_per_episode[episode_i] += 1\n",
    "            \n",
    "            if num_durations_per_episode[episode_i]>=1000:\n",
    "                break\n",
    "    \n",
    "        if episode_i % print_step == 0:\n",
    "            print(\"-------- episode %d ---------\" % episode_i)\n",
    "            test_dqn(env, policy_net, device)\n",
    "    return policy_net,num_durations_per_episode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- episode 0 ---------\n",
      "duration:  57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20631/2669109622.py:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484808560/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  non_final_next_states=torch.tensor([next_state for next_state in batch_next_state if next_state is not None],dtype=torch.float32,device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- episode 100 ---------\n",
      "duration:  34\n",
      "-------- episode 200 ---------\n",
      "duration:  26\n",
      "-------- episode 300 ---------\n",
      "duration:  195\n",
      "-------- episode 400 ---------\n",
      "duration:  294\n",
      "-------- episode 500 ---------\n",
      "duration:  383\n",
      "-------- episode 600 ---------\n",
      "duration:  2000\n",
      "-------- episode 700 ---------\n",
      "duration:  2000\n",
      "-------- episode 800 ---------\n",
      "duration:  2000\n",
      "-------- episode 900 ---------\n",
      "duration:  2000\n",
      "-------- episode 1000 ---------\n",
      "duration:  2000\n",
      "-------- episode 1100 ---------\n",
      "duration:  2000\n",
      "-------- episode 1200 ---------\n",
      "duration:  2000\n",
      "-------- episode 1300 ---------\n",
      "duration:  2000\n",
      "-------- episode 1400 ---------\n",
      "duration:  2000\n"
     ]
    }
   ],
   "source": [
    "policy_net,num_durations_per_episode=q_learning(env, 1500, experience_len=2**10, batch_size=64, alpha=1e-3, gamma=0.9, epsilon_start=0.9, epsilon_end=0.05, epsilon_decay=1000, tau=0.005,\n",
    "           device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Dict\n",
    "def plot_num_durations_per_episode(num_durations_per_episode:Dict):\n",
    "    fig,ax=plt.subplots()\n",
    "    ax.plot(num_durations_per_episode.keys(),num_durations_per_episode.values())\n",
    "plot_num_durations_per_episode(num_durations_per_episode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_1.12.1_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
